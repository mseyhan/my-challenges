{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This was a data cleaning challenge for me while I was studying. The dataset is the anti-icing early warning system of Municipality of Istanbul. The dataset includes raw data types such as unmerged and unstandardized datetime data, NA values, unmeasured datas, etc. Inside the excel file, there are different sheets which indicates the location of the values measured. Back in the days, I wanted to write a code in a holistic perspective which enables me to clean every row, and fill the rows with the exact way that I chose. Iteration through the sheets of the file was the key point to save me from being manual in this case. \n",
    "# I think the holistic mindset while approaching to the code is a great advantage while you're working with the big data. Even though I was studying and learning so that keeping things simple is a smart option, I imagined that I'm working in a bigger scaled data so that some things that I handle manually will be impossible to follow through. So I paid attention to avoid doing things manualy. I prioritized the code to realize things."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Let's see what we have inside the data\n",
    "import pandas as pd\n",
    "see_data = pd.read_excel(\"C:/Users/PC/Desktop/murat/PROGRAMMING/DATA ANALYSIS/data/buzlanma-erken-uyar-sistemi-verileri-beus-2017-2020.xlsx\",sheet_name=None)\n",
    "see_data[\"Alibahadır\"].iloc[[130,132,140]]\n",
    "# The \"///\"s are indicating the NaN values from unmeasured days, we need to clean these rows because it'll generate tracebacks. And also first two rows excluding the index are the datetime values in Turkish. We'll try to standardize and merge these two columns as one datetime64 format. The specific NaN values will be filled with the median in this case."
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Verinin Yılı  Gün / Ay Min_Hava_S_Z Min_Hava_S Maks_Hava_S_Z Maks_Hava_S  \\\n",
       "130        2018.0   8 Şubat     21:46:00       6.93      10:17:00       18.66   \n",
       "132        2018.0  10 Şubat          ///        ///           ///         ///   \n",
       "140        2018.0  18 Şubat          ///        ///           ///         ///   \n",
       "\n",
       "    Ort_Hava_S Min_Nem_Z Min_Nem Maks_NemZ  ... Min_AktuelB Maks_AktuelB_Z  \\\n",
       "130      10.55  10:22:00   49.52  01:14:00  ...         NaN            NaN   \n",
       "132        ///       ///     ///       ///  ...         NaN            NaN   \n",
       "140        ///       ///     ///       ///  ...         NaN            NaN   \n",
       "\n",
       "    Maks_AktuelB Ort_AktuelB Top_Yagis Min_Yol_S_Z Min_Yol_S Maks_Yol_S_Z  \\\n",
       "130          NaN         NaN       ///    23:30:00       5.8     10:38:00   \n",
       "132          NaN         NaN       ///         ///       ///          ///   \n",
       "140          NaN         NaN       ///         ///       ///          ///   \n",
       "\n",
       "    Maks_Yol_S Ort_Yol_S  \n",
       "130         20      9.82  \n",
       "132        ///       ///  \n",
       "140        ///       ///  \n",
       "\n",
       "[3 rows x 29 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Verinin Yılı</th>\n      <th>Gün / Ay</th>\n      <th>Min_Hava_S_Z</th>\n      <th>Min_Hava_S</th>\n      <th>Maks_Hava_S_Z</th>\n      <th>Maks_Hava_S</th>\n      <th>Ort_Hava_S</th>\n      <th>Min_Nem_Z</th>\n      <th>Min_Nem</th>\n      <th>Maks_NemZ</th>\n      <th>...</th>\n      <th>Min_AktuelB</th>\n      <th>Maks_AktuelB_Z</th>\n      <th>Maks_AktuelB</th>\n      <th>Ort_AktuelB</th>\n      <th>Top_Yagis</th>\n      <th>Min_Yol_S_Z</th>\n      <th>Min_Yol_S</th>\n      <th>Maks_Yol_S_Z</th>\n      <th>Maks_Yol_S</th>\n      <th>Ort_Yol_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>130</th>\n      <td>2018.0</td>\n      <td>8 Şubat</td>\n      <td>21:46:00</td>\n      <td>6.93</td>\n      <td>10:17:00</td>\n      <td>18.66</td>\n      <td>10.55</td>\n      <td>10:22:00</td>\n      <td>49.52</td>\n      <td>01:14:00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>///</td>\n      <td>23:30:00</td>\n      <td>5.8</td>\n      <td>10:38:00</td>\n      <td>20</td>\n      <td>9.82</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>2018.0</td>\n      <td>10 Şubat</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>2018.0</td>\n      <td>18 Şubat</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n      <td>///</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Metadata',\n",
       " 'Alibahadır',\n",
       " 'Başakşehir',\n",
       " 'Çamlıca tunel güney',\n",
       " 'Çamlıca tunel kuzey',\n",
       " 'Çiftalan',\n",
       " 'Durusu',\n",
       " 'Odayeri',\n",
       " 'Paşaköy',\n",
       " 'Riva tunel güney',\n",
       " 'Riva tunel k',\n",
       " 'Sabiha Gökçen',\n",
       " 'Subaşı',\n",
       " 'Süreyyapaşa',\n",
       " 'Uskumruköy',\n",
       " 'YSS Köprüsü',\n",
       " 'beylerbeyi',\n",
       " 'D100 gümüşyaka',\n",
       " 'D100 kumburgaz',\n",
       " 'D100 silivri',\n",
       " 'Göksu evleri',\n",
       " 'Harem rampası',\n",
       " 'İstanbul havalimanı',\n",
       " 'Kayaşehir',\n",
       " 'Kemerburgaz',\n",
       " 'Kozyatağı',\n",
       " 'TEM Çatalc Gişeler',\n",
       " 'Bakırköy Sahilyolu',\n",
       " 'Tarlabaşı',\n",
       " 'Aşiyan',\n",
       " 'Sultanbeyli',\n",
       " 'Tuzla Piyade Okulu',\n",
       " 'Şile Yolu Ömerli']"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "main_data = pd.read_excel(\"C:/Users/PC/Desktop/murat/PROGRAMMING/DATA ANALYSIS/data/buzlanma-erken-uyar-sistemi-verileri-beus-2017-2020.xlsx\",sheet_name=None,na_values=\"///\") # returns a dictionary of the excel file including all excel sheets as keys and the variable inside is the dataframe for sheets\n",
    "sheet_names = list(main_data.keys()) # returns the list including all sheet names\n",
    "sheet_names"
   ]
  },
  {
   "source": [
    "# Here I encountered such an interesting traceback, and the solution was even more interesting. Normally; here in ipynb, the code works without any problem but when I wanted to run this code in \".py\" format I was having traceback. The solution was just to write the following commentary line as \"# pylint: disable=abstract-class-instantiated\" and this made python ignore the traceback and I could move on. I wanted to have a clean excel file here outside the for loop I'm about to build.\n",
    "writer = pd.ExcelWriter('clean_sheet.xlsx',engine='xlsxwriter')# pylint: disable=abstract-class-instantiated\n",
    "writer"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.excel._xlsxwriter._XlsxWriter at 0x2a0a26fcf08>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alibahadır\n",
      "Başakşehir\n",
      "Çamlıca tunel güney\n",
      "Çamlıca tunel kuzey\n",
      "Çiftalan\n",
      "Durusu\n",
      "Odayeri\n",
      "Paşaköy\n",
      "Riva tunel güney\n",
      "Riva tunel k\n",
      "Sabiha Gökçen\n",
      "Subaşı\n",
      "Süreyyapaşa\n",
      "Uskumruköy\n",
      "YSS Köprüsü\n",
      "beylerbeyi\n",
      "D100 gümüşyaka\n",
      "D100 kumburgaz\n",
      "D100 silivri\n",
      "Göksu evleri\n",
      "Harem rampası\n",
      "İstanbul havalimanı\n",
      "Kayaşehir\n",
      "Kemerburgaz\n",
      "Kozyatağı\n",
      "TEM Çatalc Gişeler\n",
      "Bakırköy Sahilyolu\n",
      "Tarlabaşı\n",
      "Aşiyan\n",
      "Sultanbeyli\n",
      "Tuzla Piyade Okulu\n",
      "Şile Yolu Ömerli\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sheet in sheet_names[1:]: # excluding the metadata in the first sheet\n",
    "    \n",
    "    active_sheet = pd.read_excel(\"C:/Users/PC/Desktop/murat/PROGRAMMING/DATA ANALYSIS/data/buzlanma-erken-uyar-sistemi-verileri-beus-2017-2020.xlsx\",sheet_name=sheet,na_values=\"///\",skiprows=[1]) # we'll skip the first row to pass the column names, iterate through the sheet names and replace the \"///\"s with NaN.\n",
    "\n",
    "    active_sheet_med = active_sheet.median() # storing the active median in the variable\n",
    "    active_med = active_sheet_med.to_dict() # converting active_sheet_med from series to dataframe object\n",
    "    \n",
    "    for col in active_sheet: # every column name in the active sheet represented by col\n",
    "        active_col = active_sheet[col]\n",
    "        \n",
    "        if active_col.isnull().all(): # there are some columns with full of NaN values, we want to drop them\n",
    "            active_sheet.drop(columns=col,inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    active_sheet.fillna(active_med,inplace=True) # fill the NaN values with the median of the active column in the for loop\n",
    "    \n",
    "    active_sheet.to_excel(writer, sheet_name=sheet,index=False) # converting back to excel\n",
    "    print(sheet) # while iterating, i wanted to see which one is being written so added this print command\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Verinin Yılı  Gün / Ay Min_Hava_S_Z  Min_Hava_S Maks_Hava_S_Z  Maks_Hava_S  \\\n",
       "0          2017    2 Ekim     03:31:00       13.97      11:19:00        18.90   \n",
       "1          2017    3 Ekim     23:59:00        8.95      09:18:00        19.42   \n",
       "2          2017    4 Ekim     03:08:00        7.65      13:51:00        19.82   \n",
       "3          2017    5 Ekim     04:00:00        7.57      12:58:00        23.05   \n",
       "4          2017    6 Ekim     03:26:00       11.47      13:57:00        25.46   \n",
       "\n",
       "   Ort_Hava_S Min_Nem_Z  Min_Nem Maks_NemZ  ...  Maks_RuzH_Z  Maks_RuzH  \\\n",
       "0       16.37  10:40:00    51.72  03:34:00  ...     03:53:00      10.33   \n",
       "1       14.64  08:19:00    46.01  21:54:00  ...     01:01:00       8.16   \n",
       "2       13.75  08:22:00    55.43  23:58:00  ...     09:45:00       7.19   \n",
       "3       15.29  12:58:00    45.53  00:48:00  ...     11:16:00       5.77   \n",
       "4       17.53  13:53:00    37.11  23:59:00  ...     09:06:00      10.40   \n",
       "\n",
       "  Ort_RuzH  Ort_RuzY Top_Yagis  Min_Yol_S_Z  Min_Yol_S  Maks_Yol_S_Z  \\\n",
       "0     4.65     44.16      0.43     03:12:00       13.7      11:24:00   \n",
       "1     2.84    100.22      0.00     23:58:00       11.7      09:20:00   \n",
       "2     1.97    126.73      0.00     03:03:00       10.3      11:20:00   \n",
       "3     2.29    182.64      0.07     03:59:00       10.0      10:59:00   \n",
       "4     2.94    193.86     12.93     03:53:00       12.2      10:45:00   \n",
       "\n",
       "   Maks_Yol_S Ort_Yol_S  \n",
       "0        31.4     18.84  \n",
       "1        32.9     19.00  \n",
       "2        35.1     19.70  \n",
       "3        34.3     19.79  \n",
       "4        35.1     21.34  \n",
       "\n",
       "[5 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Verinin Yılı</th>\n      <th>Gün / Ay</th>\n      <th>Min_Hava_S_Z</th>\n      <th>Min_Hava_S</th>\n      <th>Maks_Hava_S_Z</th>\n      <th>Maks_Hava_S</th>\n      <th>Ort_Hava_S</th>\n      <th>Min_Nem_Z</th>\n      <th>Min_Nem</th>\n      <th>Maks_NemZ</th>\n      <th>...</th>\n      <th>Maks_RuzH_Z</th>\n      <th>Maks_RuzH</th>\n      <th>Ort_RuzH</th>\n      <th>Ort_RuzY</th>\n      <th>Top_Yagis</th>\n      <th>Min_Yol_S_Z</th>\n      <th>Min_Yol_S</th>\n      <th>Maks_Yol_S_Z</th>\n      <th>Maks_Yol_S</th>\n      <th>Ort_Yol_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017</td>\n      <td>2 Ekim</td>\n      <td>03:31:00</td>\n      <td>13.97</td>\n      <td>11:19:00</td>\n      <td>18.90</td>\n      <td>16.37</td>\n      <td>10:40:00</td>\n      <td>51.72</td>\n      <td>03:34:00</td>\n      <td>...</td>\n      <td>03:53:00</td>\n      <td>10.33</td>\n      <td>4.65</td>\n      <td>44.16</td>\n      <td>0.43</td>\n      <td>03:12:00</td>\n      <td>13.7</td>\n      <td>11:24:00</td>\n      <td>31.4</td>\n      <td>18.84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017</td>\n      <td>3 Ekim</td>\n      <td>23:59:00</td>\n      <td>8.95</td>\n      <td>09:18:00</td>\n      <td>19.42</td>\n      <td>14.64</td>\n      <td>08:19:00</td>\n      <td>46.01</td>\n      <td>21:54:00</td>\n      <td>...</td>\n      <td>01:01:00</td>\n      <td>8.16</td>\n      <td>2.84</td>\n      <td>100.22</td>\n      <td>0.00</td>\n      <td>23:58:00</td>\n      <td>11.7</td>\n      <td>09:20:00</td>\n      <td>32.9</td>\n      <td>19.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017</td>\n      <td>4 Ekim</td>\n      <td>03:08:00</td>\n      <td>7.65</td>\n      <td>13:51:00</td>\n      <td>19.82</td>\n      <td>13.75</td>\n      <td>08:22:00</td>\n      <td>55.43</td>\n      <td>23:58:00</td>\n      <td>...</td>\n      <td>09:45:00</td>\n      <td>7.19</td>\n      <td>1.97</td>\n      <td>126.73</td>\n      <td>0.00</td>\n      <td>03:03:00</td>\n      <td>10.3</td>\n      <td>11:20:00</td>\n      <td>35.1</td>\n      <td>19.70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017</td>\n      <td>5 Ekim</td>\n      <td>04:00:00</td>\n      <td>7.57</td>\n      <td>12:58:00</td>\n      <td>23.05</td>\n      <td>15.29</td>\n      <td>12:58:00</td>\n      <td>45.53</td>\n      <td>00:48:00</td>\n      <td>...</td>\n      <td>11:16:00</td>\n      <td>5.77</td>\n      <td>2.29</td>\n      <td>182.64</td>\n      <td>0.07</td>\n      <td>03:59:00</td>\n      <td>10.0</td>\n      <td>10:59:00</td>\n      <td>34.3</td>\n      <td>19.79</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017</td>\n      <td>6 Ekim</td>\n      <td>03:26:00</td>\n      <td>11.47</td>\n      <td>13:57:00</td>\n      <td>25.46</td>\n      <td>17.53</td>\n      <td>13:53:00</td>\n      <td>37.11</td>\n      <td>23:59:00</td>\n      <td>...</td>\n      <td>09:06:00</td>\n      <td>10.40</td>\n      <td>2.94</td>\n      <td>193.86</td>\n      <td>12.93</td>\n      <td>03:53:00</td>\n      <td>12.2</td>\n      <td>10:45:00</td>\n      <td>35.1</td>\n      <td>21.34</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "cleany =  pd.read_excel(\"clean_sheet.xlsx\",sheet_name=\"Alibahadır\")\n",
    "# But we see that we didn't yet standardize the date columns, they're still seperated they're not convertible to datetime64 format because of the language. The next step will be putting all in one shell and getting them ready to the datetime64 format.\n",
    "cleany.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translate = {\"Ocak\":\"Jan\", \"Şubat\":\"Feb\", \"Mart\": \"Mar\", \"Nisan\":\"Apr\", \"Mayıs\": \"May\", \"Haziran\":\"Jun\", \"Temmuz\":\"Jul\", \"Ağustos\":\"Aug\", \"Eylül\":\"Sep\", \"Ekim\":\"Oct\" ,\"Kasım\":\"Nov\", \"Aralık\":\"Dec\"} # in a dictionary, we'll store the turkish month names in keys, and english translations in values \n",
    "writer = pd.ExcelWriter('clean_sheet.xlsx',engine='xlsxwriter')# pylint: disable=abstract-class-instantiated\n",
    "\n",
    "for sheet in sheet_names[1:]:\n",
    "    \n",
    "    active_sheet = pd.read_excel(\"clean_sheet.xlsx\",sheet_name=sheet) # we're working with the recent excel file we generated\n",
    "    tl_ed = [] # this list is for translated values, we'll store them here to get them out of the following for loop\n",
    "    for value in active_sheet[\" Gün / Ay\"]:\n",
    "        day, month_tr = value.split() # splitting each row of the day column and storing these seperated values in two different variables\n",
    "        month_en = translate[month_tr] # giving the turkish name and getting the value which is english translations of month names\n",
    "        new_value = \" \".join([day,month_en]) # joining them together with a space\n",
    "        tl_ed.append(new_value) # appending the values to an outside list through the iteration\n",
    "    active_sheet[\"Verinin Yılı\"] = active_sheet[\"Verinin Yılı\"].apply(int).apply(str) # to concatenate the year values we have to turn them into strings\n",
    "    active_sheet[\" Gün / Ay\"] = tl_ed # the outside list already store the info we need, we assigned it to the related column\n",
    "    active_sheet[\" Gün / Ay\"] = active_sheet[\" Gün / Ay\"] + \" \" + active_sheet[\"Verinin Yılı\"] # now it's time to adding them together with a space in the middle\n",
    "    active_sheet.drop(columns=\"Verinin Yılı\",inplace=True) # we don't need the year column anymore so we drop it\n",
    "    active_sheet[\" Gün / Ay\"] = pd.to_datetime(active_sheet[\" Gün / Ay\"]) # at last, we converted it to the valid datetime64 format\n",
    "    active_sheet.rename(columns={\" Gün / Ay\":\"Tarih\"},inplace=True) # the dataset is turkish and we haven't fully translated the col names yet so let's stick with turkish. i'll rename the column as \"tarih\" which means \"date\" in turkish. \n",
    "    active_sheet.to_excel(writer, sheet_name=sheet,index=False) # same writing syntax here\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Tarih Min_Hava_S_Z  Min_Hava_S Maks_Hava_S_Z  Maks_Hava_S  \\\n",
       "0    2017-10-02     03:31:00       13.97      11:19:00        18.90   \n",
       "1    2017-10-03     23:59:00        8.95      09:18:00        19.42   \n",
       "2    2017-10-04     03:08:00        7.65      13:51:00        19.82   \n",
       "3    2017-10-05     04:00:00        7.57      12:58:00        23.05   \n",
       "4    2017-10-06     03:26:00       11.47      13:57:00        25.46   \n",
       "...         ...          ...         ...           ...          ...   \n",
       "998  2020-06-26     02:47:00       19.37      11:21:00        25.16   \n",
       "999  2020-06-27     22:44:00       18.75      12:28:00        25.58   \n",
       "1000 2020-06-28     02:17:00       17.28      11:57:00        26.54   \n",
       "1001 2020-06-29     23:35:00       16.03      11:24:00        27.06   \n",
       "1002 2020-06-30     02:52:00       14.68      13:58:00        30.74   \n",
       "\n",
       "      Ort_Hava_S Min_Nem_Z  Min_Nem Maks_NemZ  Maks_Nem  ...  Maks_RuzH_Z  \\\n",
       "0          16.37  10:40:00    51.72  03:34:00      96.1  ...     03:53:00   \n",
       "1          14.64  08:19:00    46.01  21:54:00      95.2  ...     01:01:00   \n",
       "2          13.75  08:22:00    55.43  23:58:00      99.5  ...     09:45:00   \n",
       "3          15.29  12:58:00    45.53  00:48:00      99.3  ...     11:16:00   \n",
       "4          17.53  13:53:00    37.11  23:59:00      89.6  ...     09:06:00   \n",
       "...          ...       ...      ...       ...       ...  ...          ...   \n",
       "998        22.82  11:23:00    74.27  02:50:00      99.7  ...     10:04:00   \n",
       "999        22.75  12:17:00    70.42  03:32:00      98.1  ...     11:03:00   \n",
       "1000       22.68  09:42:00    57.26  02:23:00      99.6  ...     09:42:00   \n",
       "1001       22.24  10:27:00    49.37  03:59:00     100.0  ...     13:54:00   \n",
       "1002       23.58  11:26:00    34.91  00:56:00      99.7  ...     10:22:00   \n",
       "\n",
       "     Maks_RuzH  Ort_RuzH Ort_RuzY  Top_Yagis  Min_Yol_S_Z  Min_Yol_S  \\\n",
       "0        10.33      4.65    44.16       0.43     03:12:00       13.7   \n",
       "1         8.16      2.84   100.22       0.00     23:58:00       11.7   \n",
       "2         7.19      1.97   126.73       0.00     03:03:00       10.3   \n",
       "3         5.77      2.29   182.64       0.07     03:59:00       10.0   \n",
       "4        10.40      2.94   193.86      12.93     03:53:00       12.2   \n",
       "...        ...       ...      ...        ...          ...        ...   \n",
       "998      11.38      2.56    52.94     273.85     02:22:00       22.2   \n",
       "999       9.84      2.56    75.91     323.33     02:36:00       21.9   \n",
       "1000      8.58      2.56   101.93     195.13     02:42:00       21.5   \n",
       "1001      5.93      2.56   127.22     239.99     03:05:00       22.0   \n",
       "1002      5.48      2.56   135.39     331.12     03:40:00       20.2   \n",
       "\n",
       "      Maks_Yol_S_Z Maks_Yol_S  Ort_Yol_S  \n",
       "0         11:24:00       31.4      18.84  \n",
       "1         09:20:00       32.9      19.00  \n",
       "2         11:20:00       35.1      19.70  \n",
       "3         10:59:00       34.3      19.79  \n",
       "4         10:45:00       35.1      21.34  \n",
       "...            ...        ...        ...  \n",
       "998       11:30:00       44.6      29.78  \n",
       "999       11:45:00       49.3      33.56  \n",
       "1000      11:36:00       53.6      35.60  \n",
       "1001      11:22:00       53.6      35.17  \n",
       "1002      11:04:00       53.8      35.62  \n",
       "\n",
       "[1003 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tarih</th>\n      <th>Min_Hava_S_Z</th>\n      <th>Min_Hava_S</th>\n      <th>Maks_Hava_S_Z</th>\n      <th>Maks_Hava_S</th>\n      <th>Ort_Hava_S</th>\n      <th>Min_Nem_Z</th>\n      <th>Min_Nem</th>\n      <th>Maks_NemZ</th>\n      <th>Maks_Nem</th>\n      <th>...</th>\n      <th>Maks_RuzH_Z</th>\n      <th>Maks_RuzH</th>\n      <th>Ort_RuzH</th>\n      <th>Ort_RuzY</th>\n      <th>Top_Yagis</th>\n      <th>Min_Yol_S_Z</th>\n      <th>Min_Yol_S</th>\n      <th>Maks_Yol_S_Z</th>\n      <th>Maks_Yol_S</th>\n      <th>Ort_Yol_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-10-02</td>\n      <td>03:31:00</td>\n      <td>13.97</td>\n      <td>11:19:00</td>\n      <td>18.90</td>\n      <td>16.37</td>\n      <td>10:40:00</td>\n      <td>51.72</td>\n      <td>03:34:00</td>\n      <td>96.1</td>\n      <td>...</td>\n      <td>03:53:00</td>\n      <td>10.33</td>\n      <td>4.65</td>\n      <td>44.16</td>\n      <td>0.43</td>\n      <td>03:12:00</td>\n      <td>13.7</td>\n      <td>11:24:00</td>\n      <td>31.4</td>\n      <td>18.84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-10-03</td>\n      <td>23:59:00</td>\n      <td>8.95</td>\n      <td>09:18:00</td>\n      <td>19.42</td>\n      <td>14.64</td>\n      <td>08:19:00</td>\n      <td>46.01</td>\n      <td>21:54:00</td>\n      <td>95.2</td>\n      <td>...</td>\n      <td>01:01:00</td>\n      <td>8.16</td>\n      <td>2.84</td>\n      <td>100.22</td>\n      <td>0.00</td>\n      <td>23:58:00</td>\n      <td>11.7</td>\n      <td>09:20:00</td>\n      <td>32.9</td>\n      <td>19.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-10-04</td>\n      <td>03:08:00</td>\n      <td>7.65</td>\n      <td>13:51:00</td>\n      <td>19.82</td>\n      <td>13.75</td>\n      <td>08:22:00</td>\n      <td>55.43</td>\n      <td>23:58:00</td>\n      <td>99.5</td>\n      <td>...</td>\n      <td>09:45:00</td>\n      <td>7.19</td>\n      <td>1.97</td>\n      <td>126.73</td>\n      <td>0.00</td>\n      <td>03:03:00</td>\n      <td>10.3</td>\n      <td>11:20:00</td>\n      <td>35.1</td>\n      <td>19.70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-10-05</td>\n      <td>04:00:00</td>\n      <td>7.57</td>\n      <td>12:58:00</td>\n      <td>23.05</td>\n      <td>15.29</td>\n      <td>12:58:00</td>\n      <td>45.53</td>\n      <td>00:48:00</td>\n      <td>99.3</td>\n      <td>...</td>\n      <td>11:16:00</td>\n      <td>5.77</td>\n      <td>2.29</td>\n      <td>182.64</td>\n      <td>0.07</td>\n      <td>03:59:00</td>\n      <td>10.0</td>\n      <td>10:59:00</td>\n      <td>34.3</td>\n      <td>19.79</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-10-06</td>\n      <td>03:26:00</td>\n      <td>11.47</td>\n      <td>13:57:00</td>\n      <td>25.46</td>\n      <td>17.53</td>\n      <td>13:53:00</td>\n      <td>37.11</td>\n      <td>23:59:00</td>\n      <td>89.6</td>\n      <td>...</td>\n      <td>09:06:00</td>\n      <td>10.40</td>\n      <td>2.94</td>\n      <td>193.86</td>\n      <td>12.93</td>\n      <td>03:53:00</td>\n      <td>12.2</td>\n      <td>10:45:00</td>\n      <td>35.1</td>\n      <td>21.34</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>2020-06-26</td>\n      <td>02:47:00</td>\n      <td>19.37</td>\n      <td>11:21:00</td>\n      <td>25.16</td>\n      <td>22.82</td>\n      <td>11:23:00</td>\n      <td>74.27</td>\n      <td>02:50:00</td>\n      <td>99.7</td>\n      <td>...</td>\n      <td>10:04:00</td>\n      <td>11.38</td>\n      <td>2.56</td>\n      <td>52.94</td>\n      <td>273.85</td>\n      <td>02:22:00</td>\n      <td>22.2</td>\n      <td>11:30:00</td>\n      <td>44.6</td>\n      <td>29.78</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>2020-06-27</td>\n      <td>22:44:00</td>\n      <td>18.75</td>\n      <td>12:28:00</td>\n      <td>25.58</td>\n      <td>22.75</td>\n      <td>12:17:00</td>\n      <td>70.42</td>\n      <td>03:32:00</td>\n      <td>98.1</td>\n      <td>...</td>\n      <td>11:03:00</td>\n      <td>9.84</td>\n      <td>2.56</td>\n      <td>75.91</td>\n      <td>323.33</td>\n      <td>02:36:00</td>\n      <td>21.9</td>\n      <td>11:45:00</td>\n      <td>49.3</td>\n      <td>33.56</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>2020-06-28</td>\n      <td>02:17:00</td>\n      <td>17.28</td>\n      <td>11:57:00</td>\n      <td>26.54</td>\n      <td>22.68</td>\n      <td>09:42:00</td>\n      <td>57.26</td>\n      <td>02:23:00</td>\n      <td>99.6</td>\n      <td>...</td>\n      <td>09:42:00</td>\n      <td>8.58</td>\n      <td>2.56</td>\n      <td>101.93</td>\n      <td>195.13</td>\n      <td>02:42:00</td>\n      <td>21.5</td>\n      <td>11:36:00</td>\n      <td>53.6</td>\n      <td>35.60</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>2020-06-29</td>\n      <td>23:35:00</td>\n      <td>16.03</td>\n      <td>11:24:00</td>\n      <td>27.06</td>\n      <td>22.24</td>\n      <td>10:27:00</td>\n      <td>49.37</td>\n      <td>03:59:00</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>13:54:00</td>\n      <td>5.93</td>\n      <td>2.56</td>\n      <td>127.22</td>\n      <td>239.99</td>\n      <td>03:05:00</td>\n      <td>22.0</td>\n      <td>11:22:00</td>\n      <td>53.6</td>\n      <td>35.17</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>2020-06-30</td>\n      <td>02:52:00</td>\n      <td>14.68</td>\n      <td>13:58:00</td>\n      <td>30.74</td>\n      <td>23.58</td>\n      <td>11:26:00</td>\n      <td>34.91</td>\n      <td>00:56:00</td>\n      <td>99.7</td>\n      <td>...</td>\n      <td>10:22:00</td>\n      <td>5.48</td>\n      <td>2.56</td>\n      <td>135.39</td>\n      <td>331.12</td>\n      <td>03:40:00</td>\n      <td>20.2</td>\n      <td>11:04:00</td>\n      <td>53.8</td>\n      <td>35.62</td>\n    </tr>\n  </tbody>\n</table>\n<p>1003 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "cleany =  pd.read_excel(\"clean_sheet.xlsx\",sheet_name=\"Alibahadır\")\n",
    "cleany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1003 entries, 0 to 1002\nData columns (total 23 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   Tarih          1003 non-null   datetime64[ns]\n 1   Min_Hava_S_Z   676 non-null    object        \n 2   Min_Hava_S     1003 non-null   float64       \n 3   Maks_Hava_S_Z  676 non-null    object        \n 4   Maks_Hava_S    1003 non-null   float64       \n 5   Ort_Hava_S     1003 non-null   float64       \n 6   Min_Nem_Z      670 non-null    object        \n 7   Min_Nem        1003 non-null   float64       \n 8   Maks_NemZ      676 non-null    object        \n 9   Maks_Nem       1003 non-null   float64       \n 10  Ort_Nem        1003 non-null   float64       \n 11  Min_RuzH_Z     676 non-null    object        \n 12  Min_RuzH       1003 non-null   float64       \n 13  Maks_RuzH_Z    676 non-null    object        \n 14  Maks_RuzH      1003 non-null   float64       \n 15  Ort_RuzH       1003 non-null   float64       \n 16  Ort_RuzY       1003 non-null   float64       \n 17  Top_Yagis      1003 non-null   float64       \n 18  Min_Yol_S_Z    674 non-null    object        \n 19  Min_Yol_S      1003 non-null   float64       \n 20  Maks_Yol_S_Z   674 non-null    object        \n 21  Maks_Yol_S     1003 non-null   float64       \n 22  Ort_Yol_S      1003 non-null   float64       \ndtypes: datetime64[ns](1), float64(14), object(8)\nmemory usage: 180.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cleany.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}